{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:39:41.284367: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 23:39:41.323980: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 23:39:41.324762: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 23:39:41.995257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pandas.plotting import scatter_matrix\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6937,
     "status": "ok",
     "timestamp": 1680802183356,
     "user": {
      "displayName": "김건",
      "userId": "00870864355609570972"
     },
     "user_tz": -540
    },
    "id": "tzS3q6qa1eUj",
    "outputId": "6d3e2ae3-5bcb-4b3b-8580-6c3c22b479f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.12.0\n",
      "Numpy version:  1.23.5\n",
      "Pandas version:  1.4.4\n",
      "Scikit-learn version:  1.0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Scikit-learn version: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = './FDD/dataset'\n",
    "SAVEPATH = './FDD/submissions'\n",
    "TEST_SIZE = 0.05\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 구현부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################추가적인 Feature Engineering Transformer를 만들어보고 성능을 테스트 하세요.#################################\n",
    "\n",
    "class PressureAttrTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        pressure = (x['out_pressure']==0.7)\n",
    "        return np.c_[x.drop(['out_pressure'], axis=1), pressure]\n",
    "    \n",
    "class LinearAttrTransformer(BaseEstimator, TransformerMixin): \n",
    "    \"\"\"\n",
    "    각 피쳐끼리 나누어주는 전처리 머신입니다. \n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        col = x.shape[-1]\n",
    "        lst = np.hsplit(x, col)\n",
    "        for i in range(col-1):\n",
    "            for j in range(i,col-1):\n",
    "                x=np.c_[x, lst[i]/(lst[j]+1e-5)]\n",
    "        return x\n",
    "    \n",
    "#################################추가적인 Feature Engineering Transformer를 만들어보고 성능을 테스트 하세요.#################################\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.9, patience=1, verbose=0,\n",
    "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0\n",
    "),\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=20, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=True\n",
    ")]\n",
    "\n",
    "def dnn(x):\n",
    "    input_dim = x.shape[1]\n",
    "    input_layer = layers.Input(shape=(input_dim, ))\n",
    "    encode = Dense(64, activation='relu')(input_layer)\n",
    "    encode = Dense(32, activation='relu')(encode)                                    \n",
    "    decode = Dense(32, activation='relu')(encode)\n",
    "    decode = Dense(64, activation='relu')(decode)\n",
    "    decode = Dense(input_dim, activation='relu')(decode)\n",
    "    autoencoder = Model(input_layer, decode)\n",
    "    autoencoder.summary()\n",
    "    return autoencoder\n",
    "\n",
    "def vis(data, model, title=False, bins=40):\n",
    "    pred = model.predict(data, verbose=0)\n",
    "    loss = np.mean(np.abs(pred - np.array(data).reshape(pred.shape)),axis = 1)\n",
    "    plt.hist(loss, bins=bins)\n",
    "    plt.xlabel(\"Train MAE loss\")\n",
    "    plt.ylabel(\"No of samples\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def train(train_dataset, test_dataset, epochs=100, batch=32):\n",
    "    models=[]\n",
    "    \n",
    "    for i in range(8):\n",
    "        print(f'===============<Train for Type{i} Started>===============\\n\\n')\n",
    "        X_train, X_val = train_test_split(train_dataset[0], test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "        model = dnn(X_train)\n",
    "        model.compile(optimizer='adam', loss='mae')\n",
    "        history = model.fit(X_train, X_train,\n",
    "                          epochs=epochs, \n",
    "                          batch_size=batch,\n",
    "                          validation_data=(X_val, X_val), \n",
    "                          callbacks=callbacks,\n",
    "                          verbose=0)\n",
    "        models.append(model)\n",
    "        print(f'===============<Train for Type{i} Finished>==============\\n\\n')\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################이 함수도 변경해 보세요.#################################\n",
    "def thirdmax_func(array):\n",
    "    return 1.5 * np.max(array)\n",
    "#################################이 함수도 변경해 보세요.#################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def threshold_definer(train_dataset, test_dataset, models, logic=thirdmax_func, bins=100):\n",
    "    thresholds=[]\n",
    "    for i in range(8):\n",
    "        train_pred=models[i].predict(train_dataset[i], verbose=0)\n",
    "        train_loss = np.mean(np.abs(train_pred - np.array(train_dataset[i]).reshape(train_pred.shape)),axis = 1)\n",
    "        test_pred=models[i].predict(test_dataset[i], verbose=0)\n",
    "        test_loss = np.mean(np.abs(test_pred - np.array(test_dataset[i]).reshape(test_pred.shape)),axis = 1)\n",
    "        threshold = 3* np.max(train_loss)\n",
    "        thresholds.append(threshold)\n",
    "        \n",
    "        plt.figure(figsize=(15,3))\n",
    "        plt.title(f'Type{i} Loss Distribution')\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.hist(train_loss, bins=bins)\n",
    "        plt.axvline(threshold, color='r')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.hist(test_loss, bins=bins)\n",
    "        plt.axvline(threshold, color='r')\n",
    "        plt.show()\n",
    "        print(\"Reconstruction error threshold:\", threshold, end='\\n\\n')\n",
    "        \n",
    "        \n",
    "    return thresholds\n",
    "\n",
    "def predict(models, test_dataset, thresholds):\n",
    "    losses=[]\n",
    "    for i in range(8):\n",
    "        preds = models[i].predict(test_dataset[i], verbose=0)\n",
    "        loss = (preds-test_dataset[i]).sum(axis=-1)\n",
    "        loss = np.where(loss>thresholds[i], 1, 0)\n",
    "        losses.append(loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N9FPo_4of2g"
   },
   "source": [
    "# 데이터 로드, type별 분리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1680802183357,
     "user": {
      "displayName": "김건",
      "userId": "00870864355609570972"
     },
     "user_tz": -540
    },
    "id": "85Prpqef4Oqw"
   },
   "outputs": [],
   "source": [
    "train_data  = pd.read_csv(os.path.join(DATAPATH, 'train_data.csv'))\n",
    "test_data  = pd.read_csv(os.path.join(DATAPATH, 'test_data.csv'))\n",
    "submission = pd.read_csv(os.path.join(DATAPATH, 'answer_sample.csv'))\n",
    "datas=[]\n",
    "pipelines=[]\n",
    "\n",
    "for i in range(8):\n",
    "    exec(f'train_type_{i} = train_data[train_data[\"type\"] == {i}].drop(\"type\", axis=1)') \n",
    "    exec(f'test_type_{i} = test_data[test_data[\"type\"] == {i}].drop(\"type\", axis=1)') \n",
    "    \n",
    "    exec(f\"pipeline{i} = Pipeline([('pressure',PressureAttrTransformer()),\\\n",
    "                                   ('linear',LinearAttrTransformer()),\\\n",
    "                                   ('scaler', MinMaxScaler())])\")\n",
    "    \n",
    "    exec(f'datas.append((train_type_{i}, test_type_{i}))')\n",
    "    exec(f'pipelines.append(pipeline{i})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=[]\n",
    "train_dataset=[]\n",
    "for data, pipeline in zip(datas, pipelines):\n",
    "    pipeline.fit(data[0])\n",
    "    train_dataset.append(pipeline.transform(data[0]))\n",
    "    test_dataset.append(pipeline.transform(data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxFjclPzkqIi"
   },
   "source": [
    "# 학습 및 threshold 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============<Train for Type0 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 23:39:44.672943: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============<Train for Type0 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type1 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "===============<Train for Type1 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type2 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "===============<Train for Type2 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type3 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "===============<Train for Type3 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type4 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "===============<Train for Type4 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type5 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "===============<Train for Type5 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type6 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "===============<Train for Type6 Finished>==============\n",
      "\n",
      "\n",
      "===============<Train for Type7 Started>===============\n",
      "\n",
      "\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 28)]              0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                1856      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,924\n",
      "Trainable params: 8,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models=train(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds=threshold_definer(train_dataset, test_dataset, models, bins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=predict(models, test_dataset, thresholds)\n",
    "submission.label=np.concatenate((losses))\n",
    "submission.to_csv(os.path.join(SAVEPATH, time.strftime(\"%m%d-%H%M.csv\")), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((losses)).sum()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMpLIj4G9Ovzmm+B03TKmBa",
   "collapsed_sections": [
    "1N9FPo_4of2g",
    "WFvgzMTpnPGL",
    "txA04bdVpA4a",
    "NxFjclPzkqIi",
    "evZJr5DRlQpR",
    "V7FpFBQvlH0R"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
